# Gist Token PoC - TDD Implementation Plan

## í”„ë¡œì íŠ¸ ê°œìš”

**ëª©í‘œ**: Gist Token ê¸°ë°˜ ë¬¸ë§¥ ì••ì¶•ì„ TDD ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í•˜ì—¬ ê°€ì •ìš© GPU(RTX 4090 24GB)ì—ì„œ íš¨ìœ¨ì ì¸ ì¥ë¬¸ ì²˜ë¦¬

**í•µì‹¬ ê°€ì„¤**: Gist Tokenì´ RAG ëŒ€ë¹„ ë©”ëª¨ë¦¬/ì†ë„ íš¨ìœ¨ì„±ì„ ìœ ì§€í•˜ë©´ì„œ Full Context ìˆ˜ì¤€ì˜ ê¸€ë¡œë²Œ ë¬¸ë§¥ ì´í•´ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆë‹¤.

**ê°œë°œ ì›ì¹™**:
- ëª¨ë¸ ì„±ëŠ¥(Loss)ì´ ì•„ë‹Œ **ë¡œì§ì˜ ì •í•©ì„±**ê³¼ **íŒŒì´í”„ë¼ì¸ ì•ˆì •ì„±**ì„ í…ŒìŠ¤íŠ¸
- í™•ë¥ ì  í•™ìŠµ ìš”ì†ŒëŠ” Sanity Checkë¡œ ê²€ì¦ (`test_overfit_one_batch`)
- í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ â‰¥ 80% (í•µì‹¬ ë¡œì§ â‰¥ 90%)

---

## Phaseë³„ ìš”ì•½

| Phase | ìƒíƒœ | ì˜ì¡´ì„± | ë³‘ë ¬ ê°€ëŠ¥ | ì˜ˆìƒ ì†Œìš” |
|-------|------|---------|----------|-----------|
| Phase 1 | âœ… ì™„ë£Œ | - | - | ì™„ë£Œ |
| Phase 2 | ğŸ”´ ëŒ€ê¸° | #1 | No | 2-3ì¼ |
| Phase 3 | ğŸ”´ ëŒ€ê¸° | #2 | No | 0.5ì¼ + GPU 6-12h |
| Phase 4 | ğŸŸ¡ ë³‘ë ¬ ê°€ëŠ¥ | - | **Yes** | 1-2ì¼ |
| Phase 5 | ğŸ”´ ëŒ€ê¸° | #3, #4 | Partial | 1-2ì¼ |
| Phase 6 | ğŸ”´ ëŒ€ê¸° | #3 | No | 1ì¼ |

**Critical Path**: Phase 2 â†’ Phase 3 â†’ Phase 6 â†’ Phase 5

---

## Phase 1: í™˜ê²½ ë° ë°ì´í„° ì¤€ë¹„ âœ… ì™„ë£Œ

**GitHub Issue**: [#1](https://github.com/kimimgo/dnsity-poc/issues/1) (Closed)

### ì™„ë£Œ í•­ëª©
- âœ… LongBench ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ (7/7 tests)
- âœ… NIAH ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (9/9 tests)
- âœ… GPU í™˜ê²½ ê²€ì¦ (RTX 4090 25.3GB)
- âœ… ë°ì´í„°ì…‹ ìƒ˜í”Œ ìƒì„± (LongBench 9.4MB + NIAH 2.0MB)

### Quality Gate
- [x] ì „ì²´ í…ŒìŠ¤íŠ¸ 29/32 í†µê³¼ (Phase 1 ê´€ë ¨ 100%)
- [x] ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ
- [x] GPU í™˜ê²½ ê²€ì¦ ì™„ë£Œ

---

## Phase 2: Gist Token êµ¬í˜„ (Critical Path)

**GitHub Issue**: [#2](https://github.com/kimimgo/dnsity-poc/issues/2)

**ì¤‘ìš”ë„**: â­â­â­â­â­ **í”„ë¡œì íŠ¸ì˜ ì„±íŒ¨ë¥¼ ê²°ì •í•˜ëŠ” Phase**

### TDD ì‘ì—… ìˆœì„œ

#### Component 1: Token Embedder & Tokenizer

**[RED] - ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸ ì‘ì„±**
```bash
# tests/unit/test_tokenizer_expansion.py
pytest tests/unit/test_tokenizer_expansion.py::test_tokenizer_expansion -v
pytest tests/unit/test_tokenizer_expansion.py::test_vocab_size_change -v
pytest tests/unit/test_tokenizer_expansion.py::test_embedding_layer_resize -v
```

**í…ŒìŠ¤íŠ¸ ë‚´ìš©**:
- Gist í† í° `<GIST_0>` ~ `<GIST_N>`ì´ tokenizerì— ì¶”ê°€ë˜ì—ˆëŠ”ì§€
- vocab_sizeê°€ ì •í™•íˆ N+1 ì¦ê°€í–ˆëŠ”ì§€
- `model.resize_token_embeddings()` í›„ shape ê²€ì¦

**[GREEN] - ìµœì†Œ êµ¬í˜„**
```python
# src/model/gist_tokenizer.py
def add_gist_tokens(tokenizer, model, num_gist_tokens):
    gist_tokens = [f"<GIST_{i}>" for i in range(num_gist_tokens)]
    tokenizer.add_special_tokens({"additional_special_tokens": gist_tokens})
    model.resize_token_embeddings(len(tokenizer))
    return tokenizer, model
```

**[REFACTOR] - ê°œì„ **
- Config íŒŒì¼ì—ì„œ `num_gist_tokens` ë¡œë“œ
- í† í° ì¶”ê°€ ë¡œì§ì„ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜ë¡œ ë¶„ë¦¬

**ê²€ì¦ ëª…ë ¹ì–´**:
```bash
pytest tests/unit/test_tokenizer_expansion.py -v --cov=src/model/gist_tokenizer --cov-report=term-missing
```

---

#### Component 2: GistDataCollator (Most Critical)

**[RED] - ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸ ì‘ì„±**
```bash
# tests/unit/test_gist_collator.py
pytest tests/unit/test_gist_collator.py::test_attention_mask_generation -v
pytest tests/unit/test_gist_collator.py::test_query_cannot_see_context -v
pytest tests/unit/test_gist_collator.py::test_query_can_see_gist -v
pytest tests/unit/test_gist_collator.py::test_gist_can_see_context -v
pytest tests/unit/test_gist_collator.py::test_batch_processing -v
```

**í…ŒìŠ¤íŠ¸ ë‚´ìš©**:
```python
def test_query_cannot_see_context():
    """Query êµ¬ê°„ì´ Contextë¥¼ ë³¼ ìˆ˜ ì—†ì–´ì•¼ í•¨"""
    input_ids = torch.tensor([[1, 2, 3, 32000, 4, 5]])  # 32000 = Gist Token
    gist_token_id = 32000

    mask = create_gist_mask(input_ids, gist_token_id)

    # Query(index 4, 5)ê°€ Context(index 2, 3)ë¥¼ ë³¼ ìˆ˜ ì—†ì–´ì•¼ í•¨
    assert mask[0, 4, 2] == 0  # or -inf depending on implementation
    assert mask[0, 4, 3] == 0
```

**[GREEN] - ìµœì†Œ êµ¬í˜„**
```python
# src/model/gist_collator.py
class GistDataCollator:
    def __call__(self, features):
        # 1. ê¸°ë³¸ causal mask ìƒì„±
        # 2. Gist token positions ì°¾ê¸°
        # 3. Query â†’ Context ì°¨ë‹¨ (mask[query_idx, context_idx] = False)
        pass
```

**[REFACTOR] - ê°œì„ **
- Tensor ì—°ì‚° ë²¡í„°í™” (for loop ì œê±°)
- Attention mask ì‹œê°í™” ìœ í‹¸ë¦¬í‹° ì¶”ê°€
- Edge case ì²˜ë¦¬ (Gistê°€ ì—†ëŠ” ê²½ìš°)

**ê²€ì¦ ëª…ë ¹ì–´**:
```bash
pytest tests/unit/test_gist_collator.py -v --cov=src/model/gist_collator --cov-report=html
# Coverage ëª©í‘œ: 100%
```

**ì‹œê°í™” ê²€ì¦** (ìˆ˜ë™):
```python
# notebooks/verify_attention_mask.ipynb
visualize_attention_mask(sample_batch)
# Expected: Query êµ¬ê°„ì´ Contextë¥¼ ë³´ì§€ ëª»í•˜ê³  Gistë§Œ ë³¼ ìˆ˜ ìˆìŒ
```

---

#### Component 3: LoRA Configuration

**[RED] - ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸ ì‘ì„±**
```bash
pytest tests/unit/test_lora_config.py::test_trainable_parameters -v
pytest tests/unit/test_lora_config.py::test_gist_embedding_gradient -v
pytest tests/unit/test_lora_config.py::test_lora_target_modules -v
```

**í…ŒìŠ¤íŠ¸ ë‚´ìš©**:
```python
def test_gist_embedding_gradient():
    """Gist í† í° ì„ë² ë”©ì— gradientê°€ íë¥´ëŠ”ì§€ ê²€ì¦"""
    model = setup_gist_model_with_lora()
    input_data = ...
    loss = model(input_data).loss
    loss.backward()

    gist_token_indices = get_gist_token_indices(tokenizer)
    gist_embed_grad = model.model.embed_tokens.weight.grad[gist_token_indices]

    assert torch.sum(torch.abs(gist_embed_grad)) > 0, "Gist Tokenì´ í•™ìŠµë˜ê³  ìˆì§€ ì•ŠìŒ!"
```

**[GREEN] - ìµœì†Œ êµ¬í˜„**
```python
# src/model/gist_lora.py
from peft import LoraConfig, get_peft_model

def setup_lora(model):
    lora_config = LoraConfig(
        r=16,
        lora_alpha=32,
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
        modules_to_save=["embed_tokens", "lm_head"],  # CRITICAL!
        lora_dropout=0.05,
        task_type="CAUSAL_LM"
    )
    return get_peft_model(model, lora_config)
```

**[REFACTOR] - ê°œì„ **
- LoRA configë¥¼ YAML íŒŒì¼ë¡œ ë¶„ë¦¬
- Gradient flow ê²€ì¦ì„ í•™ìŠµ callbackìœ¼ë¡œ ìë™í™”

**ê²€ì¦ ëª…ë ¹ì–´**:
```bash
pytest tests/unit/test_lora_config.py -v --cov=src/model/gist_lora
```

---

#### Component 4: Attention Mask Visualization

**[RED] - ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸**
```bash
pytest tests/unit/test_mask_visualization.py::test_mask_visualization_output -v
```

**[GREEN] - êµ¬í˜„**
```python
# src/utils/visualization.py
import matplotlib.pyplot as plt

def visualize_attention_mask(mask, positions):
    plt.figure(figsize=(10, 10))
    plt.imshow(mask, cmap="viridis")
    # Context/Gist/Query êµ¬ê°„ ë¼ë²¨ë§
    plt.savefig("attention_mask.png")
```

**ê²€ì¦ ëª…ë ¹ì–´**:
```bash
pytest tests/unit/test_mask_visualization.py -v
```

---

### Phase 2 Quality Gate

**í…ŒìŠ¤íŠ¸ í†µê³¼ ê¸°ì¤€**:
```bash
# ëª¨ë“  ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼
pytest tests/unit/test_tokenizer_expansion.py -v
pytest tests/unit/test_gist_collator.py -v
pytest tests/unit/test_lora_config.py -v
pytest tests/unit/test_mask_visualization.py -v

# Coverage í™•ì¸
pytest tests/unit/ --cov=src/model --cov-report=term-missing
# ëª©í‘œ: â‰¥ 90%
```

**ìˆ˜ë™ ê²€ì¦**:
- [ ] Attention mask ì‹œê°í™” ê²°ê³¼ê°€ ì„¤ê³„ ì˜ë„ì™€ ì¼ì¹˜
- [ ] Gist ì„ë² ë”© gradientê°€ 0ì´ ì•„ë‹˜ (`test_gradient_flow` í†µê³¼)

**ì™„ë£Œ ì¡°ê±´**:
- âœ… ëª¨ë“  ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ 100% í†µê³¼
- âœ… Coverage â‰¥ 90%
- âœ… Attention mask ì‹œê°ì  ê²€ì¦ ì™„ë£Œ
- âœ… Phase 3 í•™ìŠµ ì‹œì‘ ì¤€ë¹„ ì™„ë£Œ

---

## Phase 3: í•™ìŠµ ì‹¤í–‰

**GitHub Issue**: [#3](https://github.com/kimimgo/dnsity-poc/issues/3)

**ì˜ì¡´ì„±**: Phase 2 ì™„ë£Œ í•„ìˆ˜

### TDD ì‘ì—… ìˆœì„œ

#### Component 1: Trainer Sanity Check

**[RED] - ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸**
```bash
pytest tests/unit/test_trainer.py::test_overfit_one_batch -v
pytest tests/unit/test_trainer.py::test_gradient_accumulation -v
pytest tests/unit/test_trainer.py::test_checkpoint_save_load -v
pytest tests/unit/test_trainer.py::test_vram_limit -v
```

**í…ŒìŠ¤íŠ¸ ë‚´ìš©**:
```python
def test_overfit_one_batch():
    """ë‹¨ì¼ ë°°ì¹˜ 10 step í•™ìŠµ ì‹œ Lossê°€ 0ì— ìˆ˜ë ´í•˜ëŠ”ì§€"""
    model, tokenizer = setup_gist_model()
    batch = get_single_batch()

    trainer = Trainer(model=model, args=training_args)

    initial_loss = trainer.evaluate(batch)
    trainer.train(max_steps=10)
    final_loss = trainer.evaluate(batch)

    assert final_loss < initial_loss * 0.1, "ëª¨ë¸ì´ ë‹¨ì¼ ë°°ì¹˜ë¥¼ overfití•˜ì§€ ëª»í•¨!"
```

**[GREEN] - êµ¬í˜„**
```python
# src/training/train_gist.py
from transformers import Trainer, TrainingArguments

def setup_trainer(model, tokenizer, train_dataset):
    training_args = TrainingArguments(
        output_dir="checkpoints/gist-10",
        per_device_train_batch_size=1,
        gradient_accumulation_steps=8,
        learning_rate=1e-4,
        warmup_steps=100,
        max_steps=1000,
        bf16=True,
        logging_steps=10,
        save_steps=100
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        data_collator=GistDataCollator(tokenizer)
    )

    return trainer
```

**[REFACTOR]**
- Custom Trainer í´ë˜ìŠ¤ë¡œ í™•ì¥
- VRAM ëª¨ë‹ˆí„°ë§ decorator ì¶”ê°€

**ê²€ì¦ ëª…ë ¹ì–´**:
```bash
pytest tests/unit/test_trainer.py -v
```

---

#### Component 2: Experiment Configuration

**[RED] - ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸**
```bash
pytest tests/unit/test_config.py::test_load_experiment_config -v
pytest tests/unit/test_config.py::test_gist_count_variation -v
```

**[GREEN] - êµ¬í˜„**
```yaml
# experiments/configs/gist_10.yaml
model:
  name: meta-llama/Meta-Llama-3-8B-Instruct
  num_gist_tokens: 10
  quantization: 4bit

training:
  learning_rate: 1e-4
  batch_size: 1
  gradient_accumulation_steps: 8
  warmup_steps: 100
  max_steps: 1000
```

**ê²€ì¦ ëª…ë ¹ì–´**:
```bash
pytest tests/unit/test_config.py -v
```

---

#### Component 3: Training Execution (ì‹¤ì œ í•™ìŠµ)

**í•™ìŠµ ì‹¤í–‰** (í…ŒìŠ¤íŠ¸ ì•„ë‹˜):
```bash
# Experiment 1: Gist-10
python src/training/train_gist.py --config experiments/configs/gist_10.yaml

# Experiment 2: Gist-25
python src/training/train_gist.py --config experiments/configs/gist_25.yaml

# Experiment 3: Gist-50
python src/training/train_gist.py --config experiments/configs/gist_50.yaml
```

**ëª¨ë‹ˆí„°ë§**:
```bash
# VRAM ì‚¬ìš©ëŸ‰
watch -n 1 nvidia-smi

# Tensorboard
tensorboard --logdir checkpoints/
```

---

### Phase 3 Quality Gate

**í…ŒìŠ¤íŠ¸ í†µê³¼**:
```bash
pytest tests/unit/test_trainer.py -v
pytest tests/unit/test_config.py -v
```

**í•™ìŠµ ì™„ë£Œ ì¡°ê±´**:
- [ ] `test_overfit_one_batch` í†µê³¼
- [ ] 3ê°œ ì‹¤í—˜ ëª¨ë‘ ì™„ë£Œ (Gist-10/25/50)
- [ ] ê° ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ
- [ ] VRAM ì‚¬ìš©ëŸ‰ 24GB ì´ë‚´ ìœ ì§€
- [ ] Lossê°€ ìˆ˜ë ´ ê²½í–¥ í™•ì¸
- [ ] Gradient explosion ì—†ìŒ (grad_norm < 10)

---

## Phase 4: Baseline êµ¬ì¶• (ë³‘ë ¬ ê°€ëŠ¥)

**GitHub Issue**: [#4](https://github.com/kimimgo/dnsity-poc/issues/4)

**ë³‘ë ¬ ì‘ì—… ê°€ëŠ¥**: Phase 2, 3ì™€ ë…ë¦½ì ìœ¼ë¡œ ì§„í–‰ ê°€ëŠ¥

### TDD ì‘ì—… ìˆœì„œ

#### Component 1: Full Context Baseline

**[RED] - ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸**
```bash
pytest tests/unit/test_baseline.py::test_full_context_inference -v
pytest tests/unit/test_baseline.py::test_baseline_passkey_accuracy -v
pytest tests/unit/test_baseline.py::test_vram_measurement -v
```

**[GREEN] - êµ¬í˜„**
```python
# src/baseline/full_context.py
class FullContextBaseline:
    def __init__(self, model_name):
        self.model = AutoModelForCausalLM.from_pretrained(
            model_name,
            load_in_4bit=True,
            device_map="auto"
        )
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)

    def inference(self, context, question):
        prompt = f"{context}\n\nQuestion: {question}\nAnswer:"
        return self.model.generate(...)
```

**ê²€ì¦ ëª…ë ¹ì–´**:
```bash
pytest tests/unit/test_baseline.py -v --cov=src/baseline
```

---

#### Component 2: RAG Pipeline

**[RED] - ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸**
```bash
pytest tests/unit/test_rag.py::test_retrieval_correctness -v
pytest tests/unit/test_rag.py::test_top_k_retrieval -v
pytest tests/unit/test_rag.py::test_rag_end_to_end -v
```

**[GREEN] - êµ¬í˜„**
```python
# src/baseline/rag_pipeline.py
import chromadb
from sentence_transformers import SentenceTransformer

class RAGPipeline:
    def __init__(self):
        self.client = chromadb.Client()
        self.collection = self.client.create_collection("documents")
        self.embedder = SentenceTransformer("all-MiniLM-L6-v2")

    def add_documents(self, documents):
        # Chunk and embed
        pass

    def retrieve(self, query, top_k=3):
        # Vector search
        pass
```

**ê²€ì¦ ëª…ë ¹ì–´**:
```bash
pytest tests/unit/test_rag.py -v --cov=src/baseline/rag_pipeline
```

---

### Phase 4 Quality Gate

```bash
pytest tests/unit/test_baseline.py -v
pytest tests/unit/test_rag.py -v
```

**ì™„ë£Œ ì¡°ê±´**:
- [ ] Full Context baselineì´ NIAHì—ì„œ 95% ì´ìƒ ì •í™•ë„
- [ ] RAG íŒŒì´í”„ë¼ì¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ 100% í†µê³¼
- [ ] ì„±ëŠ¥ ì¸¡ì • ë¡œì§ ê²€ì¦ ì™„ë£Œ
- [ ] Coverage â‰¥ 80%

---

## Phase 5: í‰ê°€ ë° ë¶„ì„

**GitHub Issue**: [#5](https://github.com/kimimgo/dnsity-poc/issues/5)

**ì˜ì¡´ì„±**: Phase 3, 4 ì™„ë£Œ í•„ìš”

### TDD ì‘ì—… ìˆœì„œ

#### Component 1: Passkey Retrieval Metric

**[RED] - ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸**
```bash
pytest tests/unit/test_metrics.py::test_passkey_extraction -v
pytest tests/unit/test_metrics.py::test_passkey_exact_match -v
pytest tests/unit/test_metrics.py::test_passkey_edge_cases -v
```

**[GREEN] - êµ¬í˜„**
```python
# src/evaluation/metrics.py
import re

def extract_passkey(model_output):
    """ëª¨ë¸ ì¶œë ¥ì—ì„œ Passkey ì¶”ì¶œ"""
    pattern = r"[A-Z0-9]{6}"
    match = re.search(pattern, model_output)
    return match.group(0) if match else None

def passkey_accuracy(predictions, ground_truths):
    correct = sum(p == g for p, g in zip(predictions, ground_truths))
    return correct / len(predictions)
```

**ê²€ì¦ ëª…ë ¹ì–´**:
```bash
pytest tests/unit/test_metrics.py -v --cov=src/evaluation/metrics
```

---

#### Component 2: Quantitative Metrics

**[RED] - ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸**
```bash
pytest tests/unit/test_profiler.py::test_vram_measurement -v
pytest tests/unit/test_profiler.py::test_ttft_measurement -v
pytest tests/unit/test_profiler.py::test_throughput_calculation -v
```

**[GREEN] - êµ¬í˜„**
```python
# src/evaluation/profiler.py
import torch
import time

class MemoryProfiler:
    @staticmethod
    def measure_vram():
        return torch.cuda.max_memory_allocated() / 1e9  # GB

class LatencyProfiler:
    @staticmethod
    def measure_ttft(model, inputs):
        start = time.time()
        _ = model.generate(**inputs, max_new_tokens=1)
        return (time.time() - start) * 1000  # ms
```

**ê²€ì¦ ëª…ë ¹ì–´**:
```bash
pytest tests/unit/test_profiler.py -v --cov=src/evaluation/profiler
```

---

### Phase 5 Quality Gate

```bash
pytest tests/unit/test_metrics.py -v
pytest tests/unit/test_evaluator.py -v
pytest tests/unit/test_profiler.py -v
```

**ì™„ë£Œ ì¡°ê±´**:
- [ ] í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ê°€ Mock ë°ì´í„°ì—ì„œ ì •í™•í•œ ì ìˆ˜ ê³„ì‚°
- [ ] ì „ì²´ í…ŒìŠ¤íŠ¸ì…‹ í‰ê°€ ì™„ë£Œ (ì¤‘ë‹¨ ì—†ìŒ)
- [ ] ê²°ê³¼ ì‹œê°í™” ìƒì„± ì™„ë£Œ
- [ ] Coverage â‰¥ 80%

---

## Phase 6: KV Cache ì••ì¶• êµ¬í˜„

**GitHub Issue**: [#6](https://github.com/kimimgo/dnsity-poc/issues/6)

**ì˜ì¡´ì„±**: Phase 3 ì™„ë£Œ í•„ìš”

### TDD ì‘ì—… ìˆœì„œ

#### Component 1: KV Cache Manager

**[RED] - ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸**
```bash
pytest tests/unit/test_kv_cache.py::test_kv_cache_extraction -v
pytest tests/unit/test_kv_cache.py::test_kv_cache_shape_gqa -v
pytest tests/unit/test_kv_cache.py::test_kv_cache_slicing -v
pytest tests/unit/test_kv_cache.py::test_kv_value_preservation -v
```

**í…ŒìŠ¤íŠ¸ ë‚´ìš©**:
```python
def test_kv_cache_slicing():
    """Gist êµ¬ê°„ë§Œ ìŠ¬ë¼ì´ì‹±í–ˆì„ ë•Œ shape ê²€ì¦"""
    # Llama-3 8B: 32 layers, 8 kv_heads, seq_len=1000
    past_kv = create_dummy_cache(num_layers=32, num_kv_heads=8, seq_len=1000, dim=128)

    gist_indices = [999]  # Gist token at position 999
    compressed = compress_context(past_kv, gist_indices)

    # Shape should be reduced: seq_len 1000 -> ~10 (Gist only)
    assert compressed[0][0].shape[2] < 50
```

**[GREEN] - êµ¬í˜„**
```python
# src/inference/kv_cache_manager.py
def compress_context(past_key_values, gist_indices):
    """KV Cacheì—ì„œ Gist êµ¬ê°„ë§Œ ì¶”ì¶œ"""
    compressed_kv = []

    for layer_kv in past_key_values:
        key, value = layer_kv
        # Slice to keep only Gist positions
        compressed_key = key[:, :, gist_indices, :]
        compressed_value = value[:, :, gist_indices, :]
        compressed_kv.append((compressed_key, compressed_value))

    return tuple(compressed_kv)
```

**[REFACTOR]**
- KV Cacheë¥¼ íŒŒì¼ë¡œ ì €ì¥/ë¡œë“œ (torch.save/load)
- CacheManager í´ë˜ìŠ¤ë¡œ ì—¬ëŸ¬ ë¬¸ì„œ ê´€ë¦¬

**ê²€ì¦ ëª…ë ¹ì–´**:
```bash
pytest tests/unit/test_kv_cache.py -v --cov=src/inference/kv_cache_manager
# Coverage ëª©í‘œ: 90%
```

---

#### Component 2: Compressed Inference

**[RED] - ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸**
```bash
pytest tests/unit/test_compressed_inference.py::test_compressed_generation -v
pytest tests/unit/test_compressed_inference.py::test_generation_consistency -v
pytest tests/unit/test_compressed_inference.py::test_memory_saving -v
```

**[GREEN] - êµ¬í˜„**
```python
# src/inference/compressed_inference.py
def generate_with_compressed_kv(model, compressed_kv, question):
    """ì••ì¶•ëœ KV Cacheë¥¼ ì‚¬ìš©í•œ ìƒì„±"""
    inputs = tokenizer(question, return_tensors="pt")

    outputs = model.generate(
        **inputs,
        past_key_values=compressed_kv,
        max_new_tokens=100
    )

    return tokenizer.decode(outputs[0])
```

**ê²€ì¦ ëª…ë ¹ì–´**:
```bash
pytest tests/unit/test_compressed_inference.py -v
```

---

### Phase 6 Quality Gate

```bash
pytest tests/unit/test_kv_cache.py -v
pytest tests/unit/test_compressed_inference.py -v
```

**ì™„ë£Œ ì¡°ê±´**:
- [ ] ì••ì¶• ì „í›„ ìƒì„± ê²°ê³¼ ì¼ê´€ì„± í™•ì¸
- [ ] ë©”ëª¨ë¦¬ ì ˆê° íš¨ê³¼ ì…ì¦ (100x+ ì••ì¶•)
- [ ] GQA êµ¬ì¡° ì§€ì› í™•ì¸
- [ ] Coverage â‰¥ 90%

---

## ì „ì²´ ì›Œí¬í”Œë¡œìš° ìš”ì•½

### Critical Path
```
Phase 1 (ì™„ë£Œ) â†’ Phase 2 (2-3ì¼) â†’ Phase 3 (0.5ì¼ + GPU 6-12h)
                                   â†’ Phase 6 (1ì¼) â†’ Phase 5 (1-2ì¼)
```

### ë³‘ë ¬ ì‘ì—…
```
Phase 2/3 ì§„í–‰ ì¤‘ â†’ Phase 4 (1-2ì¼, ë…ë¦½ì )
Phase 3 ì§„í–‰ ì¤‘ â†’ Phase 5 í‰ê°€ ë¡œì§ (Mock ë°ì´í„°ë¡œ ë¯¸ë¦¬ ê°œë°œ)
```

### ì˜ˆìƒ ì´ ì†Œìš” ì‹œê°„
- **Sequential**: ì•½ 7-10ì¼
- **Parallel ìµœì í™”**: ì•½ 5-7ì¼ (Phase 4ë¥¼ í•™ìŠµ ì¤‘ì— ê°œë°œ)

---

## Quality Gates í†µí•© ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 2
- [ ] `pytest tests/unit/test_tokenizer_expansion.py -v` 100% í†µê³¼
- [ ] `pytest tests/unit/test_gist_collator.py -v` 100% í†µê³¼
- [ ] `pytest tests/unit/test_lora_config.py -v` 100% í†µê³¼
- [ ] Attention mask ì‹œê°í™” ê²€ì¦ ì™„ë£Œ
- [ ] Coverage â‰¥ 90%

### Phase 3
- [ ] `pytest tests/unit/test_trainer.py -v` í†µê³¼
- [ ] `test_overfit_one_batch` í†µê³¼
- [ ] Gist-10/25/50 í•™ìŠµ ì™„ë£Œ
- [ ] VRAM < 24GB ìœ ì§€

### Phase 4
- [ ] `pytest tests/unit/test_baseline.py -v` í†µê³¼
- [ ] `pytest tests/unit/test_rag.py -v` í†µê³¼
- [ ] Full Context NIAH ì •í™•ë„ â‰¥ 95%

### Phase 5
- [ ] `pytest tests/unit/test_metrics.py -v` í†µê³¼
- [ ] `pytest tests/unit/test_evaluator.py -v` í†µê³¼
- [ ] ì „ì²´ í‰ê°€ ì™„ë£Œ

### Phase 6
- [ ] `pytest tests/unit/test_kv_cache.py -v` í†µê³¼
- [ ] ì••ì¶• ì „í›„ ìƒì„± ì¼ê´€ì„± í™•ì¸
- [ ] ë©”ëª¨ë¦¬ ì ˆê° 100x+ ì…ì¦

---

## ê°œë°œ í™˜ê²½ ì„¤ì •

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸
pytest tests/ -v

# Coverage ë¦¬í¬íŠ¸
pytest tests/ --cov=src --cov-report=html

# íŠ¹ì • Phaseë§Œ
pytest tests/unit/test_gist_collator.py -v
```

### ì½”ë“œ í’ˆì§ˆ
```bash
# Linting
ruff check src/ tests/

# Type checking
mypy src/
```

### Git Workflow
```bash
# Phase 2 ì‘ì—… ì‹œì‘
git checkout -b phase-2-gist-token

# ì‘ì—… ì™„ë£Œ í›„
git add .
git commit -m "feat: Implement GistDataCollator with attention masking"
git push origin phase-2-gist-token

# PR ìƒì„±
gh pr create --title "Phase 2: Gist Token êµ¬í˜„" --body "Closes #2"
```

---

## ì„±ê³µ ê¸°ì¤€ (PoC ì™„ë£Œ)

ë³¸ í”„ë¡œì íŠ¸ê°€ ì„±ê³µí–ˆë‹¤ê³  íŒë‹¨í•˜ëŠ” ìµœì¢… ê¸°ì¤€:

1. âœ… **ë©”ëª¨ë¦¬**: Gist-25ê°€ RAGì™€ ë™ë“±í•œ VRAM (â‰¤ 10GB)
2. âœ… **ì†ë„**: TTFTê°€ RAG ëŒ€ë¹„ 30% ì´ìƒ ë‹¨ì¶•
3. âœ… **í’ˆì§ˆ**: Global Themeì—ì„œ RAG ëŒ€ë¹„ 20%p ì´ìƒ í–¥ìƒ (â‰¥ 80%)
4. âœ… **ì••ì¶• ê²€ì¦**: Passkey Accuracy â‰¥ 70%

---

## ë‹¤ìŒ ë‹¨ê³„ (PoC ì„±ê³µ í›„)

- Hierarchical Gist (ë‹¤ë‹¨ê³„ ì••ì¶•)
- Multimodal Gist (ì´ë¯¸ì§€+í…ìŠ¤íŠ¸)
- Production ë°°í¬ (vLLM í†µí•©)
- ë…¼ë¬¸ ì‘ì„± ë° ë²¤ì¹˜ë§ˆí¬ ê³µê°œ

---

## Gemini ë¶„ì„ ìš”ì•½

Gemini Proì˜ ì£¼ìš” ì¸ì‚¬ì´íŠ¸:

> **"ML í”„ë¡œì íŠ¸ì˜ TDDëŠ” ëª¨ë¸ ì„±ëŠ¥ì´ ì•„ë‹Œ ë¡œì§ì˜ ì •í•©ì„±ê³¼ íŒŒì´í”„ë¼ì¸ ì•ˆì •ì„±ì„ í…ŒìŠ¤íŠ¸í•œë‹¤"**

**Critical ë°œê²¬**:
- `GistDataCollator`ê°€ í”„ë¡œì íŠ¸ì˜ ì„±íŒ¨ë¥¼ ê²°ì •í•˜ëŠ” Critical Path
- Attention mask ë¡œì§ì˜ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ë¥¼ ë§¤ìš° ì´˜ì´˜í•˜ê²Œ ì‘ì„± í•„ìˆ˜
- Phase 4 (Baseline)ë¥¼ í•™ìŠµ ì‹œê°„ í™œìš©í•´ ë³‘ë ¬ ì§„í–‰ ê¶Œì¥
- GQA êµ¬ì¡° (num_kv_heads â‰  num_heads) ì§€ì› í•„ìˆ˜

**ì‹¤ìš©ì  TDD ì ‘ê·¼**:
- í™•ë¥ ì  í•™ìŠµì€ `test_overfit_one_batch`ë¡œ Sanity Check
- Gradient flowëŠ” backward í›„ grad ê°’ìœ¼ë¡œ ê²€ì¦
- KV CacheëŠ” Mock í…ì„œë¡œ shape ê²€ì¦
- Memory profilingì€ decoratorë¡œ ìë™í™”

---

## ì°¸ê³  ë¬¸ì„œ

- [EXPERIMENT_DESIGN.md](../../EXPERIMENT_DESIGN.md): ì‹¤í—˜ ì„¤ê³„ ìƒì„¸
- [CLAUDE.md](../../CLAUDE.md): êµ¬í˜„ ê°€ì´ë“œë¼ì¸
- [GitHub Issues #1-#6](https://github.com/kimimgo/dnsity-poc/issues): Phaseë³„ ìƒì„¸ ì‘ì—…

---

**ì‘ì„±ì¼**: 2026-01-04
**ì‘ì„±ì**: Claude Code + Gemini Pro Analysis
**ë²„ì „**: 1.0
